第三百四十一节，Python分布式爬虫打造搜索引擎Scrapy精讲—编写spiders爬虫文件循环抓取内容—meta属性返回指定值给回调函数—Scrapy内置图片下载器


			<div id="cnblogs_post_body" class="blogpost-body"><p><strong>第三百四十一节，Python分布式爬虫打造搜索引擎Scrapy精讲—编写spiders爬虫文件循环抓取内容—meta属性返回指定值给回调函数—Scrapy内置图片下载器</strong></p>
<p>&nbsp;</p>
<p><span style="color: #ff0000"><strong><strong>编写spiders爬虫文件循环抓取内容</strong></strong></span></p>
<p><span style="color: #ff0000"><strong><span style="color: #0000ff">Request()</span>方法，将指定的url地址添加到下载器下载页面，两个必须参数，</strong></span><br><strong>	　　参数：</strong><br><strong>	　　url='url'</strong><br><strong>	　　callback=页面处理函数</strong><br><strong>	　　使用时需要yield Request()</strong></p>
<p>&nbsp;</p>
<p><span style="color: #ff0000"><strong><span style="color: #0000ff">parse.urljoin()</span>方法，是urllib库下的方法，是自动url拼接，如果第二个参数的url地址是相对路径会自动与第一个参数拼接</strong></span></p>
<div class="cnblogs_code">
<pre><span style="color: #008000">#</span><span style="color: #008000"> -*- coding: utf-8 -*-</span>
<span style="color: #0000ff">import</span><span style="color: #000000"> scrapy
</span><span style="background-color: #ff99cc"><span style="color: #0000ff">from</span> scrapy.http <span style="color: #0000ff">import</span> Request</span>                             <span style="color: #008000">#</span><span style="color: #008000">导入url返回给下载器的方法</span>
<span style="background-color: #ffff00"><span style="color: #0000ff">from</span> urllib <span style="color: #0000ff">import</span> parse</span>                                    <span style="color: #008000">#</span><span style="color: #008000">导入urllib库里的parse模块</span>

<span style="color: #0000ff">class</span><span style="color: #000000"> PachSpider(scrapy.Spider):
    name </span>= <span style="color: #800000">'</span><span style="color: #800000">pach</span><span style="color: #800000">'</span><span style="color: #000000">
    allowed_domains </span>= [<span style="color: #800000">'</span><span style="color: #800000">blog.jobbole.com</span><span style="color: #800000">'</span>]                  <span style="color: #008000">#</span><span style="color: #008000">起始域名</span>
    start_urls = [<span style="color: #800000">'</span><span style="color: #800000">http://blog.jobbole.com/all-posts/</span><span style="color: #800000">'</span>]     <span style="color: #008000">#</span><span style="color: #008000">起始url</span>

    <span style="color: #0000ff">def</span><span style="color: #000000"> parse(self, response):
        </span><span style="color: #800000">"""</span><span style="color: #800000">
        获取列表页的文章url地址，交给下载器
        </span><span style="color: #800000">"""</span>
        <span style="color: #008000">#</span><span style="color: #008000">获取当前页文章url</span>
        lb_url = response.xpath(<span style="color: #800000">'</span><span style="color: #800000">//a[@class="archive-title"]/@href</span><span style="color: #800000">'</span>).extract()  <span style="color: #008000">#</span><span style="color: #008000">获取文章列表url</span>
        <span style="color: #0000ff">for</span> i <span style="color: #0000ff">in</span><span style="color: #000000"> lb_url:
            </span><span style="color: #008000">#</span><span style="color: #008000"> print(parse.urljoin(response.url,i))                                             #urllib库里的parse模块的urljoin()方法，是自动url拼接，如果第二个参数的url地址是相对路径会自动与第一个参数拼接</span>
            <span style="background-color: #ff99cc"><span style="color: #0000ff">yield</span> Request(url=<span style="background-color: #ffff00">parse.urljoin(response.url, i)</span>, callback=self.parse_wzhang)</span>      <span style="color: #008000">#</span><span style="color: #008000">将循环到的文章url添加给下载器，下载后交给parse_wzhang回调函数</span>

        <span style="color: #008000">#</span><span style="color: #008000">获取下一页列表url,交给下载器，返回给parse函数循环</span>
        x_lb_url = response.xpath(<span style="color: #800000">'</span><span style="color: #800000">//a[@class="next page-numbers"]/@href</span><span style="color: #800000">'</span>).extract()         <span style="color: #008000">#</span><span style="color: #008000">获取下一页文章列表url</span>
        <span style="color: #0000ff">if</span><span style="color: #000000"> x_lb_url:
            </span><span style="background-color: #ff99cc"><span style="color: #0000ff">yield</span> Request(url=<span style="background-color: #ffff00">parse.urljoin(response.url, x_lb_url[0])</span>, callback=self.parse)</span>     <span style="color: #008000">#</span><span style="color: #008000">获取到下一页url返回给下载器，回调给parse函数循环进行</span>


    <span style="color: #0000ff">def</span><span style="color: #000000"> parse_wzhang(self,response):
        title </span>= response.xpath(<span style="color: #800000">'</span><span style="color: #800000">//div[@class="entry-header"]/h1/text()</span><span style="color: #800000">'</span>).extract()           <span style="color: #008000">#</span><span style="color: #008000">获取文章标题</span>
        <span style="color: #0000ff">print</span>(title)</pre>
</div>
<p><img src="https://images2017.cnblogs.com/blog/955761/201708/955761-20170804175254365-957939229.png" alt=""></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="color: #ff0000"><strong>Request()函数在返回url时，同时可以通过meta属性返回一个自定义字典给回调函数</strong></span></p>
<div class="cnblogs_code">
<pre><span style="color: #008000">#</span><span style="color: #008000"> -*- coding: utf-8 -*-</span>
<span style="color: #0000ff">import</span><span style="color: #000000"> scrapy
</span><span style="color: #0000ff">from</span> scrapy.http <span style="color: #0000ff">import</span> Request                             <span style="color: #008000">#</span><span style="color: #008000">导入url返回给下载器的方法</span>
<span style="color: #0000ff">from</span> urllib <span style="color: #0000ff">import</span> parse                                    <span style="color: #008000">#</span><span style="color: #008000">导入urllib库里的parse模块</span>
<span style="color: #0000ff">from</span> adc.items <span style="color: #0000ff">import</span> AdcItem                               <span style="color: #008000">#</span><span style="color: #008000">导入items数据接收模块的接收类</span>

<span style="color: #0000ff">class</span><span style="color: #000000"> PachSpider(scrapy.Spider):
    name </span>= <span style="color: #800000">'</span><span style="color: #800000">pach</span><span style="color: #800000">'</span><span style="color: #000000">
    allowed_domains </span>= [<span style="color: #800000">'</span><span style="color: #800000">blog.jobbole.com</span><span style="color: #800000">'</span>]                  <span style="color: #008000">#</span><span style="color: #008000">起始域名</span>
    start_urls = [<span style="color: #800000">'</span><span style="color: #800000">http://blog.jobbole.com/all-posts/</span><span style="color: #800000">'</span>]     <span style="color: #008000">#</span><span style="color: #008000">起始url</span>

    <span style="color: #0000ff">def</span><span style="color: #000000"> parse(self, response):
        </span><span style="color: #800000">"""</span><span style="color: #800000">
        获取列表页的文章url地址，交给下载器
        </span><span style="color: #800000">"""</span>
        <span style="color: #008000">#</span><span style="color: #008000">获取当前页文章url</span>
        <span style="background-color: #ff99cc">lb = response.css(<span style="color: #800000">'</span><span style="color: #800000">div .post.floated-thumb</span><span style="color: #800000">'</span>)</span>  <span style="color: #008000">#</span><span style="color: #008000">获取文章列表区块,css选择器</span>
        <span style="color: #008000">#</span><span style="color: #008000"> print(lb)</span>
        <span style="color: #0000ff">for</span> i <span style="color: #0000ff">in</span><span style="color: #000000"> lb:
            <span style="background-color: #ff99cc">lb_url </span></span><span style="background-color: #ff99cc">= i.css(<span style="color: #800000">'</span><span style="color: #800000">.archive-title ::attr(href)</span><span style="color: #800000">'</span>).extract_first(<span style="color: #800000">''</span>)</span>     <span style="color: #008000">#</span><span style="color: #008000">获取区块里文章url</span>
            <span style="color: #008000">#</span><span style="color: #008000"> print(lb_url)</span>
<span style="background-color: #ffff00"><span style="color: #000000">
            lb_img </span>= i.css(<span style="color: #800000">'</span><span style="color: #800000">.post-thumb img ::attr(src)</span><span style="color: #800000">'</span>).extract_first(<span style="color: #800000">''</span>)</span>     <span style="color: #008000">#</span><span style="color: #008000">获取区块里文章缩略图</span>
            <span style="color: #008000">#</span><span style="color: #008000"> print(lb_img)</span>

            <span style="color: #0000ff">yield</span> Request(<span style="background-color: #ff99cc">url=parse.urljoin(response.url, lb_url)</span>, <span style="background-color: #ffff00">meta={<span style="color: #800000">'</span><span style="color: #800000">lb_img</span><span style="color: #800000">'</span>:parse.urljoin(response.url, lb_img)}</span>, callback=self.parse_wzhang)      <span style="color: #008000">#</span><span style="color: #008000">将循环到的文章url添加给下载器，下载后交给parse_wzhang回调函数</span>

        <span style="color: #008000">#</span><span style="color: #008000">获取下一页列表url,交给下载器，返回给parse函数循环</span>
        x_lb_url = response.css(<span style="color: #800000">'</span><span style="color: #800000">.next.page-numbers ::attr(href)</span><span style="color: #800000">'</span>).extract_first(<span style="color: #800000">''</span>)         <span style="color: #008000">#</span><span style="color: #008000">获取下一页文章列表url</span>
        <span style="color: #0000ff">if</span><span style="color: #000000"> x_lb_url:
            </span><span style="color: #0000ff">yield</span> Request(url=parse.urljoin(response.url, x_lb_url), callback=self.parse)     <span style="color: #008000">#</span><span style="color: #008000">获取到下一页url返回给下载器，回调给parse函数循环进行</span>


    <span style="color: #0000ff">def</span><span style="color: #000000"> parse_wzhang(self,response):
        title </span>= response.css(<span style="color: #800000">'</span><span style="color: #800000">.entry-header h1 ::text</span><span style="color: #800000">'</span>).extract()           <span style="color: #008000">#</span><span style="color: #008000">获取文章标题</span>
        <span style="color: #008000">#</span><span style="color: #008000"> print(title)</span>
<span style="background-color: #ffff00"><span style="color: #000000">
        tp_img </span>= response.meta.get(<span style="color: #800000">'</span><span style="color: #800000">lb_img</span><span style="color: #800000">'</span>, <span style="color: #800000">''</span>)</span>                            <span style="color: #008000">#</span><span style="color: #008000">接收meta传过来的值，用get获取防止出错</span>
        <span style="color: #008000">#</span><span style="color: #008000"> print(tp_img)</span>
<span style="color: #000000">
        shjjsh </span>= AdcItem()                                                                   <span style="color: #008000">#</span><span style="color: #008000">实例化数据接收类</span>
        shjjsh[<span style="color: #800000">'</span><span style="color: #800000">title</span><span style="color: #800000">'</span>] = title                                                              <span style="color: #008000">#</span><span style="color: #008000">将数据传输给items接收模块的指定类</span>
        shjjsh[<span style="color: #800000">'</span><span style="color: #800000">img</span><span style="color: #800000">'</span>] =<span style="color: #000000"> tp_img

        </span><span style="color: #0000ff">yield</span> shjjsh                                <span style="color: #008000">#</span><span style="color: #008000">将接收对象返回给pipelines.py处理模块</span></pre>
</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<hr>
<p>&nbsp;</p>
<p><span style="color: #ff0000"><strong>Scrapy内置图片下载器使用</strong></span></p>
<p><span style="color: #000000; background-color: #ffffff"><strong><strong>Scrapy给我们内置了一个图片下载器在<span style="color: #0000ff">crapy.pipelines.images.<span style="background-color: #ff99cc">ImagesPipeline</span></span>，专门用于将爬虫抓取到图片url后将图片下载到本地</strong></strong></span></p>
<p>&nbsp;</p>
<p><span style="background-color: #ffff00"><span style="color: #ff0000"><strong><strong>第一步、</strong></strong></span><span style="color: #ff0000"><strong><strong>爬虫抓取图片URL地址后，<span style="color: #0000ff">填充到&nbsp;items.py文件的容器函数</span></strong></strong></span></span></p>
<p>&nbsp;</p>
<p><span style="color: #ff0000; background-color: #ffffff"><strong><strong><span style="color: #0000ff">　　<span style="color: #000000">爬虫文件</span></span></strong></strong></span></p>
<div class="cnblogs_code">
<pre><span style="color: #008000">#</span><span style="color: #008000"> -*- coding: utf-8 -*-</span>
<span style="color: #0000ff">import</span><span style="color: #000000"> scrapy
</span><span style="color: #0000ff">from</span> scrapy.http <span style="color: #0000ff">import</span> Request                             <span style="color: #008000">#</span><span style="color: #008000">导入url返回给下载器的方法</span>
<span style="color: #0000ff">from</span> urllib <span style="color: #0000ff">import</span> parse                                    <span style="color: #008000">#</span><span style="color: #008000">导入urllib库里的parse模块</span>
<span style="color: #0000ff">from</span> adc.items <span style="color: #0000ff">import</span> AdcItem                               <span style="color: #008000">#</span><span style="color: #008000">导入items数据接收模块的接收类</span>

<span style="color: #0000ff">class</span><span style="color: #000000"> PachSpider(scrapy.Spider):
    name </span>= <span style="color: #800000">'</span><span style="color: #800000">pach</span><span style="color: #800000">'</span><span style="color: #000000">
    allowed_domains </span>= [<span style="color: #800000">'</span><span style="color: #800000">blog.jobbole.com</span><span style="color: #800000">'</span>]                  <span style="color: #008000">#</span><span style="color: #008000">起始域名</span>
    start_urls = [<span style="color: #800000">'</span><span style="color: #800000">http://blog.jobbole.com/all-posts/</span><span style="color: #800000">'</span>]     <span style="color: #008000">#</span><span style="color: #008000">起始url</span>

    <span style="color: #0000ff">def</span><span style="color: #000000"> parse(self, response):
        </span><span style="color: #800000">"""</span><span style="color: #800000">
        获取列表页的文章url地址，交给下载器
        </span><span style="color: #800000">"""</span>
        <span style="color: #008000">#</span><span style="color: #008000">获取当前页文章url</span>
        lb = response.css(<span style="color: #800000">'</span><span style="color: #800000">div .post.floated-thumb</span><span style="color: #800000">'</span>)  <span style="color: #008000">#</span><span style="color: #008000">获取文章列表区块,css选择器</span>
        <span style="color: #008000">#</span><span style="color: #008000"> print(lb)</span>
        <span style="color: #0000ff">for</span> i <span style="color: #0000ff">in</span><span style="color: #000000"> lb:
            lb_url </span>= i.css(<span style="color: #800000">'</span><span style="color: #800000">.archive-title ::attr(href)</span><span style="color: #800000">'</span>).extract_first(<span style="color: #800000">''</span>)     <span style="color: #008000">#</span><span style="color: #008000">获取区块里文章url</span>
            <span style="color: #008000">#</span><span style="color: #008000"> print(lb_url)</span>
<span style="background-color: #ff99cc"><span style="color: #000000">
            lb_img </span>= i.css(<span style="color: #800000">'</span><span style="color: #800000">.post-thumb img ::attr(src)</span><span style="color: #800000">'</span>).extract_first(<span style="color: #800000">''</span>)</span>     <span style="color: #008000">#</span><span style="color: #008000">获取区块里文章缩略图</span>
            <span style="color: #008000">#</span><span style="color: #008000"> print(lb_img)</span>

            <span style="color: #0000ff">yield</span> Request(url=parse.urljoin(response.url, lb_url), <span style="background-color: #ff99cc">meta={<span style="color: #800000">'</span><span style="color: #800000">lb_img</span><span style="color: #800000">'</span>:parse.urljoin(response.url, lb_img)}</span>, callback=self.parse_wzhang)      <span style="color: #008000">#</span><span style="color: #008000">将循环到的文章url添加给下载器，下载后交给parse_wzhang回调函数</span>

        <span style="color: #008000">#</span><span style="color: #008000">获取下一页列表url,交给下载器，返回给parse函数循环</span>
        x_lb_url = response.css(<span style="color: #800000">'</span><span style="color: #800000">.next.page-numbers ::attr(href)</span><span style="color: #800000">'</span>).extract_first(<span style="color: #800000">''</span>)         <span style="color: #008000">#</span><span style="color: #008000">获取下一页文章列表url</span>
        <span style="color: #0000ff">if</span><span style="color: #000000"> x_lb_url:
            </span><span style="color: #0000ff">yield</span> Request(url=parse.urljoin(response.url, x_lb_url), callback=self.parse)     <span style="color: #008000">#</span><span style="color: #008000">获取到下一页url返回给下载器，回调给parse函数循环进行</span>


    <span style="color: #0000ff">def</span><span style="color: #000000"> parse_wzhang(self,response):
        title </span>= response.css(<span style="color: #800000">'</span><span style="color: #800000">.entry-header h1 ::text</span><span style="color: #800000">'</span>).extract()           <span style="color: #008000">#</span><span style="color: #008000">获取文章标题</span>
        <span style="color: #008000">#</span><span style="color: #008000"> print(title)</span>
<span style="background-color: #ff99cc"><span style="color: #000000">
        tp_img </span>= response.meta.get(<span style="color: #800000">'</span><span style="color: #800000">lb_img</span><span style="color: #800000">'</span>, <span style="color: #800000">''</span>)</span>                            <span style="color: #008000">#</span><span style="color: #008000">接收meta传过来的值，用get获取防止出错</span>
        <span style="color: #008000">#</span><span style="color: #008000"> print(tp_img)</span>
<span style="color: #000000">
        shjjsh </span>= AdcItem()                                                                   <span style="color: #008000">#</span><span style="color: #008000">实例化数据接收类</span>
        shjjsh[<span style="color: #800000">'</span><span style="color: #800000">title</span><span style="color: #800000">'</span>] = title                                                              <span style="color: #008000">#</span><span style="color: #008000">将数据传输给items接收模块的指定类</span>
        <span style="background-color: #ff99cc"><span style="background-color: #ffff00">shjjsh[<span style="color: #800000">'</span><span style="color: #800000">img</span><span style="color: #800000">'</span>] =<span style="color: #000000"> [tp_img]

        </span><span style="color: #0000ff">yield</span> shjjsh</span></span>                                <span style="color: #008000">#</span><span style="color: #008000">将接收对象返回给pipelines.py处理模块</span></pre>
</div>
<p>&nbsp;</p>
<p><span style="color: #ff0000; background-color: #ffff00"><strong>第二步、设置<span style="color: #0000ff">&nbsp;</span><strong><strong><span style="color: #0000ff">items.py</span> 文件的容器函数，接收爬虫获取到的数据填充</strong></strong></strong></span></p>
<p>&nbsp;</p>
<div class="cnblogs_code">
<pre><span style="color: #008000">#</span><span style="color: #008000"> -*- coding: utf-8 -*-</span>

<span style="color: #008000">#</span><span style="color: #008000"> Define here the models for your scraped items</span><span style="color: #008000">
#
#</span><span style="color: #008000"> See documentation in:</span><span style="color: #008000">
#</span><span style="color: #008000"> http://doc.scrapy.org/en/latest/topics/items.html</span>

<span style="color: #0000ff">import</span><span style="color: #000000"> scrapy

</span><span style="color: #008000">#</span><span style="color: #008000">items.py,文件是专门用于，接收爬虫获取到的数据信息的，就相当于是容器文件</span>

<span style="color: #0000ff">class</span> AdcItem(scrapy.Item):    <span style="color: #008000">#</span><span style="color: #008000">设置爬虫获取到的信息容器类</span>
    title = scrapy.Field()     <span style="color: #008000">#</span><span style="color: #008000">接收爬虫获取到的title信息</span>
    <span style="background-color: #ffff00">img = scrapy.Field()       <span style="color: #008000">#</span><span style="color: #008000">接收缩略图</span></span>
    <span style="background-color: #ffff00">img_tplj = scrapy.Field()  <span style="color: #008000">#</span><span style="color: #008000">图片保存路径</span></span></pre>
</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="color: #ff0000; background-color: #ffff00"><strong>第三步、在<span style="color: #0000ff">pipelines.py</span>使用crapy内置的图片下载器</strong></span></p>
<p><span style="color: #ff0000"><strong>1、首先引入内置图片下载器</strong></span></p>
<p><span style="color: #ff0000"><strong>2、自定义一个图片下载内，继承crapy内置的<span style="color: #0000ff">ImagesPipeline</span>图片下载器类</strong></span></p>
<p><span style="color: #ff0000"><strong>3、使用<span style="color: #0000ff">ImagesPipeline</span>类里的<span style="color: #0000ff">item_completed()</span>方法获取到图片下载后的保存路径</strong></span></p>
<p><span style="color: #ff0000"><strong>4、在<span style="color: #0000ff">settings.py</span>设置文件里，注册自定义图片下载器类，和设置图片保存路径</strong></span></p>
<p>&nbsp;</p>
<div class="cnblogs_code">
<pre><span style="color: #008000">#</span><span style="color: #008000"> -*- coding: utf-8 -*-</span>

<span style="color: #008000">#</span><span style="color: #008000"> Define your item pipelines here</span><span style="color: #008000">
#
#</span><span style="color: #008000"> Don't forget to add your pipeline to the ITEM_PIPELINES setting</span><span style="color: #008000">
#</span><span style="color: #008000"> See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>
<span style="color: #0000ff">from</span> scrapy.pipelines.images <span style="color: #0000ff">import</span> ImagesPipeline  <span style="color: #008000">#</span><span style="color: #008000">导入图片下载器模块</span>


<span style="color: #0000ff">class</span> AdcPipeline(object):                      <span style="color: #008000">#</span><span style="color: #008000">定义数据处理类，必须继承object</span>
    <span style="color: #0000ff">def</span> process_item(self, item, spider):       <span style="color: #008000">#</span><span style="color: #008000">process_item(item)为数据处理函数，接收一个item，item里就是爬虫最后yield item 来的数据对象</span>
        <span style="color: #0000ff">print</span>(<span style="color: #800000">'</span><span style="color: #800000">文章标题是：</span><span style="color: #800000">'</span> + item[<span style="color: #800000">'</span><span style="color: #800000">title</span><span style="color: #800000">'</span><span style="color: #000000">][0])
        </span><span style="color: #0000ff">print</span>(<span style="color: #800000">'</span><span style="color: #800000">文章缩略图url是：</span><span style="color: #800000">'</span> + item[<span style="color: #800000">'</span><span style="color: #800000">img</span><span style="color: #800000">'</span><span style="color: #000000">][0])
        </span><span style="background-color: #ffff00"><span style="color: #0000ff">print</span>(<span style="color: #800000">'</span><span style="color: #800000">文章缩略图保存路径是：</span><span style="color: #800000">'</span> + item[<span style="color: #800000">'</span><span style="color: #800000">img_tplj</span><span style="color: #800000">'</span>])  <span style="color: #008000">#</span><span style="color: #008000">接收图片下载器填充的，图片下载后的路径</span></span>

        <span style="color: #0000ff">return</span><span style="color: #000000"> item

</span><span style="background-color: #ff99cc"><span style="color: #0000ff">class</span> imgPipeline(ImagesPipeline):                      <span style="color: #008000">#</span><span style="color: #008000">自定义一个图片下载内，继承crapy内置的ImagesPipeline图片下载器类</span>
    <span style="color: #0000ff">def</span> item_completed(self, results, item, info):      <span style="color: #008000">#</span><span style="color: #008000">使用ImagesPipeline类里的item_completed()方法获取到图片下载后的保存路径</span>
        <span style="color: #0000ff">for</span> ok, value <span style="color: #0000ff">in</span><span style="color: #000000"> results:
            img_lj </span>= value[<span style="color: #800000">'</span><span style="color: #800000">path</span><span style="color: #800000">'</span>]     <span style="color: #008000">#</span><span style="color: #008000">接收图片保存路径</span>
            <span style="color: #008000">#</span><span style="color: #008000"> print(ok)</span>
            item[<span style="color: #800000">'</span><span style="color: #800000">img_tplj</span><span style="color: #800000">'</span>] = img_lj  <span style="color: #008000">#</span><span style="color: #008000">将图片保存路径填充到items.py里的字段里</span>
        <span style="color: #0000ff">return</span> item                    <span style="color: #008000">#</span><span style="color: #008000">将item给items.py 文件的容器函数</span>
</span>
    <span style="background-color: #ffff00"><span style="color: #008000">#</span><span style="color: #008000">注意：自定义图片下载器设置好后，需要在</span></span></pre>
</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="color: #ff0000"><strong>在settings.py设置文件里，注册自定义图片下载器类，和设置图片保存路径</strong></span></p>
<p><span style="color: #ff0000"><strong><span style="color: #0000ff">IMAGES_URLS_FIELD</span> 设置要下载图片的url地址，一般设置的items.py里接收的字段</strong></span><br><span style="color: #ff0000"><strong><span style="color: #0000ff">IMAGES_STORE</span> 设置图片保存路径</strong></span></p>
<div class="cnblogs_code">
<pre><span style="color: #008000">#</span><span style="color: #008000"> Configure item pipelines</span><span style="color: #008000">
#</span><span style="color: #008000"> See http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.html</span>
ITEM_PIPELINES =<span style="color: #000000"> {
   </span><span style="color: #800000">'</span><span style="color: #800000">adc.pipelines.AdcPipeline</span><span style="color: #800000">'</span>: 300,  <span style="color: #008000">#</span><span style="color: #008000">注册adc.pipelines.AdcPipeline类，后面一个数字参数表示执行等级，</span>
   <span style="background-color: #ffff00"><span style="color: #800000">'</span><span style="color: #800000">adc.pipelines.imgPipeline</span><span style="color: #800000">'</span>: 1,    <span style="color: #008000">#</span><span style="color: #008000">注册自定义图片下载器,数值越小，越优先执行</span></span>
<span style="color: #000000">}

<span style="background-color: #ffff00">IMAGES_URLS_FIELD </span></span><span style="background-color: #ffff00">= <span style="color: #800000">'</span><span style="color: #800000">img</span><span style="color: #800000">'</span></span>                             <span style="color: #008000">#</span><span style="color: #008000">设置要下载图片的url字段，就是图片在items.py里的字段里</span>
lujin = os.path.abspath(os.path.dirname(<span style="color: #800080">__file__</span><span style="color: #000000">))
<span style="background-color: #ffff00">IMAGES_STORE </span></span><span style="background-color: #ffff00">= os.path.join(lujin, <span style="color: #800000">'</span><span style="color: #800000">img</span><span style="color: #800000">'</span>)             <span style="color: #008000">#</span><span style="color: #008000">设置图片保存路径</span></span></pre>
</div>
<p><img src="https://images2017.cnblogs.com/blog/955761/201708/955761-20170805173551475-2024993375.png" alt=""></p>
<p>&nbsp;</p></div>