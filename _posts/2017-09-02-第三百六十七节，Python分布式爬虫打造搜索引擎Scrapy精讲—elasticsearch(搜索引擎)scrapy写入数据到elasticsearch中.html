第三百六十七节，Python分布式爬虫打造搜索引擎Scrapy精讲—elasticsearch(搜索引擎)scrapy写入数据到elasticsearch中


			<div id="cnblogs_post_body" class="blogpost-body"><p><strong>第三百六十七节，Python分布式爬虫打造搜索引擎Scrapy精讲—elasticsearch(搜索引擎)scrapy写入数据到elasticsearch中</strong></p>
<p>&nbsp;</p>
<p><strong>前面我们讲到的elasticsearch(搜索引擎)操作，如：增、删、改、查等操作都是用的elasticsearch的语言命令，就像sql命令一样，当然<strong>elasticsearch官方也提供了一个python操作<strong>elasticsearch(搜索引擎)的接口包，就像sqlalchemy操作数据库一样的ORM框，这样我们操作<strong>elasticsearch就不用写命令了，用<span style="color: #ff0000">elasticsearch-dsl-py</span>这个模块来操作，也就是用python的方式操作一个类即可</strong></strong></strong></strong></p>
<p>&nbsp;</p>
<p><span style="color: #ff0000"><strong><strong><strong><strong><strong><strong><strong><strong>elasticsearch-dsl-py下载</strong></strong></strong></strong></strong></strong></strong></strong></span></p>
<p><strong><strong><strong><strong><strong><strong><strong><strong>下载地址：</strong><span style="color: #0000ff">https://github.com/elastic/elasticsearch-dsl-py</span></strong></strong></strong></strong></strong></strong></strong></p>
<p><strong><strong><strong><strong><strong><strong><strong><span style="color: #0000ff"><span style="color: #000000">文档说明</span>：http://elasticsearch-dsl.readthedocs.io/en/latest/</span></strong></strong></strong></strong></strong></strong></strong></p>
<p><span style="color: #000000"><strong><strong><strong><strong><strong><strong><strong>首先安装好<strong><strong><strong><strong><strong><strong><strong><strong><span style="color: #ff0000">elasticsearch-dsl-py</span>模块</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></span></p>
<p>&nbsp;</p>
<p><span style="color: #ff0000; background-color: #ffff00"><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>1、elasticsearch-dsl模块使用说明</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></span></p>
<p><span style="color: #ff0000"><strong><span style="color: #0000ff">create_connection(hosts=['127.0.0.1'])</span>：连接elasticsearch(搜索引擎)服务器方法，可以连接多台服务器</strong></span><br><span style="color: #ff0000"><strong><span style="color: #0000ff">class Meta</span>：设置索引名称和表名称</strong></span><br><span style="color: #ff0000"><strong><span style="color: #0000ff">索引类名称.init()</span>: 生成索引和表以及字段</strong></span><br><span style="color: #ff0000"><strong><span style="color: #0000ff">实例化索引类.save()</span>:将数据写入elasticsearch(搜索引擎)</strong></span></p>
<p>&nbsp;</p>
<p><span style="color: #ff0000"><strong>elasticsearch_orm.py 操作<strong>elasticsearch(搜索引擎)文件</strong></strong></span></p>
<div class="cnblogs_code">
<pre><span style="color: #008000">#</span><span style="color: #008000">!/usr/bin/env python</span><span style="color: #008000">
#</span><span style="color: #008000"> -*- coding:utf8 -*-</span>
<span style="color: #0000ff">from</span> datetime <span style="color: #0000ff">import</span><span style="color: #000000"> datetime
</span><span style="background-color: #ff99cc"><span style="color: #0000ff">from</span> elasticsearch_dsl <span style="color: #0000ff">import</span><span style="color: #000000"> DocType, Date, Nested, Boolean, \
    analyzer, InnerObjectWrapper, Completion, Keyword, Text, Integer

</span><span style="color: #008000">#</span><span style="color: #008000"> 更多字段类型见第三百六十四节elasticsearch(搜索引擎)的mapping映射管理</span>

<span style="color: #0000ff">from</span> elasticsearch_dsl.connections <span style="color: #0000ff">import</span> connections       <span style="color: #008000">#</span><span style="color: #008000"> 导入连接elasticsearch(搜索引擎)服务器方法</span>
connections.create_connection(hosts=[<span style="color: #800000">'</span><span style="color: #800000">127.0.0.1</span><span style="color: #800000">'</span><span style="color: #000000">])


</span><span style="color: #0000ff">class</span> lagouType(DocType):                                                   <span style="color: #008000">#</span><span style="color: #008000"> 自定义一个类来继承DocType类</span>
    <span style="color: #008000">#</span><span style="color: #008000"> Text类型需要分词，所以需要知道中文分词器，ik_max_wordwei为中文分词器</span>
    title = Text(analyzer=<span style="color: #800000">"</span><span style="color: #800000">ik_max_word</span><span style="color: #800000">"</span>)                                    <span style="color: #008000">#</span><span style="color: #008000"> 设置，字段名称=字段类型，Text为字符串类型并且可以分词建立倒排索引</span>
    description = Text(analyzer=<span style="color: #800000">"</span><span style="color: #800000">ik_max_word</span><span style="color: #800000">"</span><span style="color: #000000">)
    keywords </span>= Text(analyzer=<span style="color: #800000">"</span><span style="color: #800000">ik_max_word</span><span style="color: #800000">"</span><span style="color: #000000">)
    url </span>= Keyword()                                                         <span style="color: #008000">#</span><span style="color: #008000"> 设置，字段名称=字段类型，Keyword为普通字符串类型，不分词</span>
    riqi = Date()                                                           <span style="color: #008000">#</span><span style="color: #008000"> 设置，字段名称=字段类型，Date日期类型</span>

    <span style="color: #0000ff">class</span> Meta:                                                             <span style="color: #008000">#</span><span style="color: #008000"> Meta是固定写法</span>
        index = <span style="color: #800000">"</span><span style="color: #800000">lagou</span><span style="color: #800000">"</span>                                                     <span style="color: #008000">#</span><span style="color: #008000"> 设置索引名称(相当于数据库名称)</span>
        doc_type = <span style="color: #800000">'</span><span style="color: #800000">biao</span><span style="color: #800000">'</span>                                                   <span style="color: #008000">#</span><span style="color: #008000"> 设置表名称</span>

<span style="color: #0000ff">if</span> <span style="color: #800080">__name__</span> == <span style="color: #800000">"</span><span style="color: #800000">__main__</span><span style="color: #800000">"</span>:          <span style="color: #008000">#</span><span style="color: #008000"> 判断在本代码文件执行才执行里面的方法，其他页面调用的则不执行里面的方法</span>
    lagouType.init()                <span style="color: #008000">#</span><span style="color: #008000"> 生成elasticsearch(搜索引擎)的索引，表，字段等信息</span></span>


<span style="color: #008000">#</span><span style="color: #008000"> 使用方法说明：</span><span style="background-color: #ffff99"><span style="color: #008000">
#</span><span style="color: #008000"> 在要要操作elasticsearch(搜索引擎)的页面，导入此模块</span><span style="color: #008000">
#</span><span style="color: #008000"> lagou = lagouType()           #实例化类</span><span style="color: #008000">
#</span><span style="color: #008000"> lagou.title = '值'            #要写入字段=值</span><span style="color: #008000">
#</span><span style="color: #008000"> lagou.description = '值'</span><span style="color: #008000">
#</span><span style="color: #008000"> lagou.keywords = '值'</span><span style="color: #008000">
#</span><span style="color: #008000"> lagou.url = '值'</span><span style="color: #008000">
#</span><span style="color: #008000"> lagou.riqi = '值'</span><span style="color: #008000">
#</span><span style="color: #008000"> lagou.save()                  #将数据写入elasticsearch(搜索引擎)</span></span></pre>
</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="color: #ff0000"><strong>2、scrapy写入数据到elasticsearch中</strong></span></p>
<p><span style="color: #ff0000"><strong>爬虫文件</strong></span></p>
<div class="cnblogs_code">
<pre><span style="color: #008000">#</span><span style="color: #008000"> -*- coding: utf-8 -*-</span>
<span style="color: #0000ff">import</span><span style="color: #000000"> scrapy
</span><span style="color: #0000ff">from</span> scrapy.linkextractors <span style="color: #0000ff">import</span><span style="color: #000000"> LinkExtractor
</span><span style="color: #0000ff">from</span> scrapy.spiders <span style="color: #0000ff">import</span><span style="color: #000000"> CrawlSpider, Rule
</span><span style="background-color: #ff99cc"><span style="color: #0000ff">from</span> adc.items <span style="color: #0000ff">import</span> LagouItem,LagouItemLoader  <span style="color: #008000">#</span><span style="color: #008000">导入items容器类,和ItemLoader类</span></span>
<span style="color: #0000ff">import</span><span style="color: #000000"> time


</span><span style="color: #0000ff">class</span> LagouSpider(CrawlSpider):                     <span style="color: #008000">#</span><span style="color: #008000">创建爬虫类</span>
    name = <span style="color: #800000">'</span><span style="color: #800000">lagou</span><span style="color: #800000">'</span>                                  <span style="color: #008000">#</span><span style="color: #008000">爬虫名称</span>
    allowed_domains = [<span style="color: #800000">'</span><span style="color: #800000">www.luyin.org</span><span style="color: #800000">'</span>]             <span style="color: #008000">#</span><span style="color: #008000">起始域名</span>
    start_urls = [<span style="color: #800000">'</span><span style="color: #800000">http://www.luyin.org/</span><span style="color: #800000">'</span>]          <span style="color: #008000">#</span><span style="color: #008000">起始url</span>
<span style="color: #000000">
    custom_settings </span>=<span style="color: #000000"> {
        </span><span style="color: #800000">"</span><span style="color: #800000">AUTOTHROTTLE_ENABLED</span><span style="color: #800000">"</span>: True,                             <span style="color: #008000">#</span><span style="color: #008000">覆盖掉settings.py里的相同设置，开启COOKIES</span>
        <span style="color: #800000">"</span><span style="color: #800000">DOWNLOAD_DELAY</span><span style="color: #800000">"</span>:5<span style="color: #000000">
    }

    rules </span>=<span style="color: #000000"> (
        </span><span style="color: #008000">#</span><span style="color: #008000">配置抓取列表页规则</span>
        Rule(LinkExtractor(allow=(<span style="color: #800000">'</span><span style="color: #800000">ggwa/.*</span><span style="color: #800000">'</span>)), follow=<span style="color: #000000">True),

        </span><span style="color: #008000">#</span><span style="color: #008000">配置抓取内容页规则</span>
        Rule(LinkExtractor(allow=(<span style="color: #800000">'</span><span style="color: #800000">post/\d+.html.*</span><span style="color: #800000">'</span>)), callback=<span style="color: #800000">'</span><span style="color: #800000">parse_job</span><span style="color: #800000">'</span>, follow=<span style="color: #000000">True),
    )

    </span><span style="color: #0000ff">def</span> parse_job(self, response):                  <span style="color: #008000">#</span><span style="color: #008000">回调函数，注意：因为CrawlS模板的源码创建了parse回调函数，所以切记我们不能创建parse名称的函数</span>
        atime = time.localtime(time.time())         <span style="color: #008000">#</span><span style="color: #008000">获取系统当前时间</span>
        dqatime = <span style="color: #800000">"</span><span style="color: #800000">{0}-{1}-{2} {3}:{4}:{5}</span><span style="color: #800000">"</span><span style="color: #000000">.format(
            atime.tm_year,
            atime.tm_mon,
            atime.tm_mday,
            atime.tm_hour,
            atime.tm_min,
            atime.tm_sec
        )  </span><span style="color: #008000">#</span><span style="color: #008000"> 将格式化时间日期，单独取出来拼接成一个完整日期</span>
<span style="color: #000000">
        url </span>=<span style="color: #000000"> response.url

        <span style="background-color: #ff99cc">item_loader </span></span><span style="background-color: #ff99cc">= LagouItemLoader(LagouItem(), response=response)   <span style="color: #008000">#</span><span style="color: #008000"> 将数据填充进items.py文件的LagouItem</span>
        item_loader.add_xpath(<span style="color: #800000">'</span><span style="color: #800000">title</span><span style="color: #800000">'</span>, <span style="color: #800000">'</span><span style="color: #800000">/html/head/title/text()</span><span style="color: #800000">'</span><span style="color: #000000">)
        item_loader.add_xpath(</span><span style="color: #800000">'</span><span style="color: #800000">description</span><span style="color: #800000">'</span>, <span style="color: #800000">'</span><span style="color: #800000">/html/head/meta[@name="Description"]/@content</span><span style="color: #800000">'</span><span style="color: #000000">)
        item_loader.add_xpath(</span><span style="color: #800000">'</span><span style="color: #800000">keywords</span><span style="color: #800000">'</span>, <span style="color: #800000">'</span><span style="color: #800000">/html/head/meta[@name="keywords"]/@content</span><span style="color: #800000">'</span><span style="color: #000000">)
        item_loader.add_value(</span><span style="color: #800000">'</span><span style="color: #800000">url</span><span style="color: #800000">'</span><span style="color: #000000">, url)
        item_loader.add_value(</span><span style="color: #800000">'</span><span style="color: #800000">riqi</span><span style="color: #800000">'</span><span style="color: #000000">, dqatime)
        article_item </span>=<span style="color: #000000"> item_loader.load_item()
</span><span style="color: #0000ff">yield</span> article_item</span></pre>
</div>
<p>&nbsp;</p>
<p><span style="color: #ff0000"><strong>items.py文件</strong></span></p>
<div class="cnblogs_code">
<pre><span style="color: #008000">#</span><span style="color: #008000"> -*- coding: utf-8 -*-</span>

<span style="color: #008000">#</span><span style="color: #008000"> Define here the models for your scraped items</span><span style="color: #008000">
#
#</span><span style="color: #008000"> See documentation in:</span><span style="color: #008000">
#</span><span style="color: #008000"> http://doc.scrapy.org/en/latest/topics/items.html</span><span style="color: #008000">
#</span><span style="color: #008000">items.py,文件是专门用于，接收爬虫获取到的数据信息的，就相当于是容器文件</span>

<span style="color: #0000ff">import</span><span style="color: #000000"> scrapy
</span><span style="color: #0000ff">from</span> scrapy.loader.processors <span style="color: #0000ff">import</span><span style="color: #000000"> MapCompose,TakeFirst
</span><span style="color: #0000ff">from</span> scrapy.loader <span style="color: #0000ff">import</span> ItemLoader                <span style="color: #008000">#</span><span style="color: #008000">导入ItemLoader类也就加载items容器类填充数据</span>
<span style="background-color: #ffff00"><span style="color: #0000ff">from</span> adc.models.elasticsearch_orm <span style="color: #0000ff">import</span> lagouType  <span style="color: #008000">#</span><span style="color: #008000">导入elasticsearch操作模块</span></span>

<span style="background-color: #ff99cc"><span style="color: #0000ff">class</span> LagouItemLoader(ItemLoader):                  <span style="color: #008000">#</span><span style="color: #008000">自定义Loader继承ItemLoader类，在爬虫页面调用这个类填充数据到Item类</span>
    default_output_processor = TakeFirst()          <span style="color: #008000">#</span><span style="color: #008000">默认利用ItemLoader类，加载items容器类填充数据，是列表类型，可以通过TakeFirst()方法，获取到列表里的内容</span>


<span style="color: #0000ff">def</span> tianjia(value):                                 <span style="color: #008000">#</span><span style="color: #008000">自定义数据预处理函数</span>
    <span style="color: #0000ff">return</span> value                                    <span style="color: #008000">#</span><span style="color: #008000">将处理后的数据返给Item</span>


<span style="color: #0000ff">class</span> LagouItem(scrapy.Item):                       <span style="color: #008000">#</span><span style="color: #008000">设置爬虫获取到的信息容器类</span>
    title = scrapy.Field(                           <span style="color: #008000">#</span><span style="color: #008000">接收爬虫获取到的title信息</span>
        input_processor=MapCompose(tianjia),        <span style="color: #008000">#</span><span style="color: #008000">将数据预处理函数名称传入MapCompose方法里处理，数据预处理函数的形式参数value会自动接收字段title</span>
<span style="color: #000000">    )
    description </span>=<span style="color: #000000"> scrapy.Field()
    keywords </span>=<span style="color: #000000"> scrapy.Field()
    url </span>=<span style="color: #000000"> scrapy.Field()
    riqi </span>=<span style="color: #000000"> scrapy.Field()

    </span><span style="background-color: #ffff00"><span style="color: #0000ff">def</span><span style="color: #000000"> save_to_es(self):
        lagou </span>= lagouType()                         <span style="color: #008000">#</span><span style="color: #008000"> 实例化elasticsearch(搜索引擎对象)</span>
        lagou.title = self[<span style="color: #800000">'</span><span style="color: #800000">title</span><span style="color: #800000">'</span>]                 <span style="color: #008000">#</span><span style="color: #008000"> 字段名称=值</span>
        lagou.description = self[<span style="color: #800000">'</span><span style="color: #800000">description</span><span style="color: #800000">'</span><span style="color: #000000">]
        lagou.keywords </span>= self[<span style="color: #800000">'</span><span style="color: #800000">keywords</span><span style="color: #800000">'</span><span style="color: #000000">]
        lagou.url </span>= self[<span style="color: #800000">'</span><span style="color: #800000">url</span><span style="color: #800000">'</span><span style="color: #000000">]
        lagou.riqi </span>= self[<span style="color: #800000">'</span><span style="color: #800000">riqi</span><span style="color: #800000">'</span><span style="color: #000000">]
        lagou.save()                                </span><span style="color: #008000">#</span><span style="color: #008000"> 将数据写入elasticsearch(搜索引擎对象)</span>
        <span style="color: #0000ff">return</span></span></span></pre>
</div>
<p>&nbsp;</p>
<p><span style="color: #ff0000"><strong>pipelines.py文件</strong></span></p>
<div class="cnblogs_code">
<pre><span style="color: #008000">#</span><span style="color: #008000"> -*- coding: utf-8 -*-</span>

<span style="color: #008000">#</span><span style="color: #008000"> Define your item pipelines here</span><span style="color: #008000">
#
#</span><span style="color: #008000"> Don't forget to add your pipeline to the ITEM_PIPELINES setting</span><span style="color: #008000">
#</span><span style="color: #008000"> See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>
<span style="color: #0000ff">from</span> adc.models.elasticsearch_orm <span style="color: #0000ff">import</span> lagouType  <span style="color: #008000">#</span><span style="color: #008000">导入elasticsearch操作模块</span>

<span style="color: #0000ff">class</span><span style="color: #000000"> AdcPipeline(object):
    </span><span style="color: #0000ff">def</span><span style="color: #000000"> process_item(self, item, spider):

        </span><span style="color: #008000">#</span><span style="color: #008000">也可以在这里将数据写入elasticsearch搜索引擎，这里的缺点是统一处理</span>
        <span style="color: #008000">#</span><span style="color: #008000"> lagou = lagouType()</span>
        <span style="color: #008000">#</span><span style="color: #008000"> lagou.title = item['title']</span>
        <span style="color: #008000">#</span><span style="color: #008000"> lagou.description = item['description']</span>
        <span style="color: #008000">#</span><span style="color: #008000"> lagou.keywords = item['keywords']</span>
        <span style="color: #008000">#</span><span style="color: #008000"> lagou.url = item['url']</span>
        <span style="color: #008000">#</span><span style="color: #008000"> lagou.riqi = item['riqi']</span>
        <span style="color: #008000">#</span><span style="color: #008000"> lagou.save()</span>
        <span style="background-color: #ffff00">item.save_to_es()       <span style="color: #008000">#</span><span style="color: #008000">执行items.py文件的save_to_es方法将数据写入elasticsearch搜索引擎</span></span>
        <span style="color: #0000ff">return</span> item</pre>
</div>
<p>&nbsp;</p>
<p><span style="color: #ff0000"><strong>settings.py文件，注册pipelines</strong></span></p>
<div class="cnblogs_code">
<pre><span style="color: #008000">#</span><span style="color: #008000"> Configure item pipelines</span><span style="color: #008000">
#</span><span style="color: #008000"> See http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.html</span>
<span style="background-color: #ffff00">ITEM_PIPELINES =<span style="color: #000000"> {
   </span><span style="color: #800000">'</span><span style="color: #800000">adc.pipelines.AdcPipeline</span><span style="color: #800000">'</span>: 300<span style="color: #000000">,
}</span></span></pre>
</div>
<p>&nbsp;</p>
<p><span style="color: #ff0000"><strong>main.py爬虫启动文件</strong></span></p>
<div class="cnblogs_code">
<pre><span style="color: #008000">#</span><span style="color: #008000">!/usr/bin/env python</span><span style="color: #008000">
#</span><span style="color: #008000"> -*- coding:utf8 -*-</span>

<span style="color: #0000ff">from</span> scrapy.cmdline <span style="color: #0000ff">import</span> execute  <span style="color: #008000">#</span><span style="color: #008000">导入执行scrapy命令方法</span>
<span style="color: #0000ff">import</span><span style="color: #000000"> sys
</span><span style="color: #0000ff">import</span><span style="color: #000000"> os

sys.path.append(os.path.join(os.getcwd())) </span><span style="color: #008000">#</span><span style="color: #008000">给Python解释器，添加模块新路径 ,将main.py文件所在目录添加到Python解释器</span>
<span style="background-color: #ffff00"><span style="color: #000000">
execute([</span><span style="color: #800000">'</span><span style="color: #800000">scrapy</span><span style="color: #800000">'</span>, <span style="color: #800000">'</span><span style="color: #800000">crawl</span><span style="color: #800000">'</span>, <span style="color: #800000">'</span><span style="color: #800000">lagou</span><span style="color: #800000">'</span>, <span style="color: #800000">'</span><span style="color: #800000">--nolog</span><span style="color: #800000">'</span>])  <span style="color: #008000">#</span><span style="color: #008000">执行scrapy命令</span></span>

<span style="color: #008000">#</span><span style="color: #008000"> execute(['scrapy', 'crawl', 'lagou'])  #执行scrapy命令</span></pre>
</div>
<p>&nbsp;</p>
<p><span style="color: #ff0000"><strong>运行爬虫</strong></span></p>
<p><span style="color: #ff0000"><strong><img src="https://images2017.cnblogs.com/blog/955761/201709/955761-20170903001850015-918115174.png" alt=""></strong></span></p>
<p>&nbsp;</p>
<p><span style="color: #ff0000"><strong>写入elasticsearch(搜索引擎)情况</strong></span></p>
<p><span style="color: #ff0000"><strong><img src="https://images2017.cnblogs.com/blog/955761/201709/955761-20170903002037108-538224057.png" alt=""></strong></span></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>补充：<strong><strong><strong><strong><strong><strong><strong><strong>elasticsearch-dsl &nbsp;的 增删改查</strong></strong></strong></strong></strong></strong></strong></strong></p>
<div class="cnblogs_code">
<pre><span style="color: #008000">#</span><span style="color: #008000">!/usr/bin/env python</span><span style="color: #008000">
#</span><span style="color: #008000"> -*- coding:utf8 -*-</span>
<span style="color: #0000ff">from</span> datetime <span style="color: #0000ff">import</span><span style="color: #000000"> datetime
</span><span style="background-color: #ff99cc"><span style="color: #0000ff">from</span> elasticsearch_dsl <span style="color: #0000ff">import</span><span style="color: #000000"> DocType, Date, Nested, Boolean, \
    analyzer, InnerObjectWrapper, Completion, Keyword, Text, Integer

</span></span><span style="color: #008000">#</span><span style="color: #008000"> 更多字段类型见第三百六十四节elasticsearch(搜索引擎)的mapping映射管理</span>

<span style="background-color: #ff99cc"><span style="color: #0000ff">from</span> elasticsearch_dsl.connections <span style="color: #0000ff">import</span> connections       <span style="color: #008000">#</span><span style="color: #008000"> 导入连接elasticsearch(搜索引擎)服务器方法</span>
connections.create_connection(hosts=[<span style="color: #800000">'</span><span style="color: #800000">127.0.0.1</span><span style="color: #800000">'</span><span style="color: #000000">])


</span><span style="color: #0000ff">class</span> lagouType(DocType):                                                   <span style="color: #008000">#</span><span style="color: #008000"> 自定义一个类来继承DocType类</span>
    <span style="color: #008000">#</span><span style="color: #008000"> Text类型需要分词，所以需要知道中文分词器，ik_max_wordwei为中文分词器</span>
    title = Text(analyzer=<span style="color: #800000">"</span><span style="color: #800000">ik_max_word</span><span style="color: #800000">"</span>)                                    <span style="color: #008000">#</span><span style="color: #008000"> 设置，字段名称=字段类型，Text为字符串类型并且可以分词建立倒排索引</span>
    description = Text(analyzer=<span style="color: #800000">"</span><span style="color: #800000">ik_max_word</span><span style="color: #800000">"</span><span style="color: #000000">)
    keywords </span>= Text(analyzer=<span style="color: #800000">"</span><span style="color: #800000">ik_max_word</span><span style="color: #800000">"</span><span style="color: #000000">)
    url </span>= Keyword()                                                         <span style="color: #008000">#</span><span style="color: #008000"> 设置，字段名称=字段类型，Keyword为普通字符串类型，不分词</span>
    riqi = Date()                                                           <span style="color: #008000">#</span><span style="color: #008000"> 设置，字段名称=字段类型，Date日期类型</span>

    <span style="color: #0000ff">class</span> Meta:                                                             <span style="color: #008000">#</span><span style="color: #008000"> Meta是固定写法</span>
        index = <span style="color: #800000">"</span><span style="color: #800000">lagou</span><span style="color: #800000">"</span>                                                     <span style="color: #008000">#</span><span style="color: #008000"> 设置索引名称(相当于数据库名称)</span>
        doc_type = <span style="color: #800000">'</span><span style="color: #800000">biao</span><span style="color: #800000">'</span>                                                   <span style="color: #008000">#</span><span style="color: #008000"> 设置表名称</span>

<span style="color: #0000ff">if</span> <span style="color: #800080">__name__</span> == <span style="color: #800000">"</span><span style="color: #800000">__main__</span><span style="color: #800000">"</span>:          <span style="color: #008000">#</span><span style="color: #008000"> 判断在本代码文件执行才执行里面的方法，其他页面调用的则不执行里面的方法</span>
    lagouType.init()                <span style="color: #008000">#</span><span style="color: #008000"> 生成elasticsearch(搜索引擎)的索引，表，字段等信息</span></span>


<span style="color: #008000">#</span><span style="color: #008000"> 使用方法说明：</span><span style="color: #008000">
#</span><span style="color: #008000"> 在要要操作elasticsearch(搜索引擎)的页面，导入此模块</span><span style="color: #008000">
#</span><span style="color: #008000"> lagou = lagouType()           #实例化类</span><span style="color: #008000">
#</span><span style="color: #008000"> lagou.title = '值'            #要写入字段=值</span><span style="color: #008000">
#</span><span style="color: #008000"> lagou.description = '值'</span><span style="color: #008000">
#</span><span style="color: #008000"> lagou.keywords = '值'</span><span style="color: #008000">
#</span><span style="color: #008000"> lagou.url = '值'</span><span style="color: #008000">
#</span><span style="color: #008000"> lagou.riqi = '值'</span><span style="color: #008000">
#</span><span style="color: #008000"> lagou.save()                  #将数据写入elasticsearch(搜索引擎)</span></pre>
</div>
<p>&nbsp;</p>
<p>1新增数据</p>
<div class="cnblogs_code">
<pre><span style="color: #0000ff">from</span> adc.models.elasticsearch_orm <span style="color: #0000ff">import</span> lagouType  <span style="color: #008000">#</span><span style="color: #008000">导入刚才配置的elasticsearch操作模块</span>
<span style="color: #000000">
　　　　　lagou </span>= lagouType()                         <span style="color: #008000">#</span><span style="color: #008000"> 实例化elasticsearch(搜索引擎对象)<br>　　　　　<span style="background-color: #ff99cc; color: #000000">lagou._id = 1　　　　　　　　　　　　　#自定义ID，很重要，以后都是根据ID来操作</span><br></span>
        lagou.title = self[<span style="color: #800000">'</span><span style="color: #800000">title</span><span style="color: #800000">'</span>]                 <span style="color: #008000">#</span><span style="color: #008000"> 字段名称=值</span>
        lagou.description = self[<span style="color: #800000">'</span><span style="color: #800000">description</span><span style="color: #800000">'</span><span style="color: #000000">]
        lagou.keywords </span>= self[<span style="color: #800000">'</span><span style="color: #800000">keywords</span><span style="color: #800000">'</span><span style="color: #000000">]
        lagou.url </span>= self[<span style="color: #800000">'</span><span style="color: #800000">url</span><span style="color: #800000">'</span><span style="color: #000000">]
        lagou.riqi </span>= self[<span style="color: #800000">'</span><span style="color: #800000">riqi</span><span style="color: #800000">'</span><span style="color: #000000">]
        lagou.save()                                </span><span style="color: #008000">#</span><span style="color: #008000"> 将数据写入elasticsearch(搜索引擎对象)</span></pre>
</div>
<p>&nbsp;</p>
<p>2删除指定数据</p>
<div class="cnblogs_code">
<pre>　　</pre>
<pre>from adc.models.elasticsearch_orm import lagouType  #导入刚才配置的elasticsearch操作模块</pre>
<pre>sousuo_orm = lagouType()                    <span style="color: #008000">#</span><span style="color: #008000"> 实例化</span>
sousuo_orm.get(id=1).delete()               <span style="color: #008000">#</span><span style="color: #008000"> 删除id等于1的数据</span></pre>
</div>
<p>&nbsp;</p>
<p>3修改指定的数据</p>
<div class="cnblogs_code">
<pre><span style="color: #0000ff">from</span> adc.models.elasticsearch_orm <span style="color: #0000ff">import</span> lagouType  <span style="color: #008000">#</span><span style="color: #008000">导入刚才配置的elasticsearch操作模块</span>
<span style="color: #000000">
sousuo_orm </span>= lagouType()                           <span style="color: #008000">#</span><span style="color: #008000"> 实例化</span>
sousuo_orm.get(id=1).update(title=<span style="color: #800000">'</span><span style="color: #800000">123456789</span><span style="color: #800000">'</span>)     <span style="color: #008000">#</span><span style="color: #008000"> 修改id等于1的数据</span></pre>
</div>
<p>以上全部使用<strong><strong><strong><strong><strong><strong><strong><strong>elasticsearch-dsl模块</strong></strong></strong></strong></strong></strong></strong></strong></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><strong>注意下面使用的原生elasticsearch模块</strong></p>
<p>删除指定使用，就是相当于删除指定数据库</p>
<p>使用原生elasticsearch模块删除指定索引</p>
<div class="cnblogs_code">
<pre><span style="color: #0000ff">from</span> elasticsearch <span style="color: #0000ff">import</span> Elasticsearch                                     <span style="color: #008000">#</span><span style="color: #008000"> 导入原生的elasticsearch(搜索引擎)接口</span>
client = Elasticsearch(hosts=settings.Elasticsearch_hosts)                  <span style="color: #008000">#</span><span style="color: #008000"> 连接原生的elasticsearch</span>

<span style="color: #008000">#</span><span style="color: #008000"> 使用原生elasticsearch模块删除指定索引</span><span style="color: #008000">
#</span><span style="color: #008000">要做容错处理，如果索引不存在会报错</span>
            <span style="color: #0000ff">try</span><span style="color: #000000">:
                <span style="background-color: #ff99cc">client.indices.delete(index</span></span><span style="background-color: #ff99cc">=<span style="color: #800000">'</span><span style="color: #800000">jxiou_zuopin</span><span style="color: #800000">'</span><span style="color: #000000">)
            </span></span><span style="color: #0000ff">except</span><span style="color: #000000"> Exception as e:
                </span><span style="color: #0000ff">pass</span></pre>
</div>
<p>原生查询</p>
<div class="cnblogs_code">
<pre><span style="color: #0000ff">from</span> elasticsearch <span style="color: #0000ff">import</span> Elasticsearch                 <span style="color: #008000">#</span><span style="color: #008000"> 导入原生的elasticsearch(搜索引擎)接口</span>
            client = Elasticsearch(hosts=Elasticsearch_hosts)       <span style="color: #008000">#</span><span style="color: #008000"> 连接原生的elasticsearch</span>
<span style="color: #000000">

response </span>= client.search(                               <span style="color: #008000">#</span><span style="color: #008000"> 原生的elasticsearch接口的search()方法，就是搜索，可以支持原生elasticsearch语句查询</span>
                index=<span style="color: #800000">"</span><span style="color: #800000">jxiou_zuopin</span><span style="color: #800000">"</span>,                               <span style="color: #008000">#</span><span style="color: #008000"> 设置索引名称</span>
                doc_type=<span style="color: #800000">"</span><span style="color: #800000">zuopin</span><span style="color: #800000">"</span>,                                  <span style="color: #008000">#</span><span style="color: #008000"> 设置表名称</span>
                body={                                              <span style="color: #008000">#</span><span style="color: #008000"> 书写elasticsearch语句</span>
                    <span style="color: #800000">"</span><span style="color: #800000">query</span><span style="color: #800000">"</span><span style="color: #000000">: {
                        </span><span style="color: #800000">"</span><span style="color: #800000">multi_match</span><span style="color: #800000">"</span>: {                            <span style="color: #008000">#</span><span style="color: #008000"> multi_match查询</span>
                            <span style="color: #800000">"</span><span style="color: #800000">query</span><span style="color: #800000">"</span>: sousuoci,                      <span style="color: #008000">#</span><span style="color: #008000"> 查询关键词</span>
                            <span style="color: #800000">"</span><span style="color: #800000">fields</span><span style="color: #800000">"</span>: [<span style="color: #800000">"</span><span style="color: #800000">title</span><span style="color: #800000">"</span>]                     <span style="color: #008000">#</span><span style="color: #008000"> 查询字段</span>
<span style="color: #000000">                        }
                    },
                    </span><span style="color: #800000">"</span><span style="color: #800000">from</span><span style="color: #800000">"</span>: (page - 1) * tiaoshu,                   <span style="color: #008000">#</span><span style="color: #008000"> 从第几条开始获取</span>
                    <span style="color: #800000">"</span><span style="color: #800000">size</span><span style="color: #800000">"</span>: tiaoshu,                                <span style="color: #008000">#</span><span style="color: #008000"> 获取多少条数据</span>
                    <span style="color: #800000">"</span><span style="color: #800000">highlight</span><span style="color: #800000">"</span>: {                                  <span style="color: #008000">#</span><span style="color: #008000"> 查询关键词高亮处理</span>
                        <span style="color: #800000">"</span><span style="color: #800000">pre_tags</span><span style="color: #800000">"</span>: [<span style="color: #800000">'</span><span style="color: #800000">&lt;span class="gaoliang"&gt;</span><span style="color: #800000">'</span>],    <span style="color: #008000">#</span><span style="color: #008000"> 高亮开始标签</span>
                        <span style="color: #800000">"</span><span style="color: #800000">post_tags</span><span style="color: #800000">"</span>: [<span style="color: #800000">'</span><span style="color: #800000">&lt;/span&gt;</span><span style="color: #800000">'</span>],                   <span style="color: #008000">#</span><span style="color: #008000"> 高亮结束标签</span>
                        <span style="color: #800000">"</span><span style="color: #800000">fields</span><span style="color: #800000">"</span>: {                                 <span style="color: #008000">#</span><span style="color: #008000"> 高亮设置</span>
                            <span style="color: #800000">"</span><span style="color: #800000">title</span><span style="color: #800000">"</span>: {}                             <span style="color: #008000">#</span><span style="color: #008000"> 高亮字段</span>
<span style="color: #000000">                        }
                    }
                }
            )
            </span><span style="color: #008000">#</span><span style="color: #008000"> 开始获取数据</span>
            total_nums = response[<span style="color: #800000">"</span><span style="color: #800000">hits</span><span style="color: #800000">"</span>][<span style="color: #800000">"</span><span style="color: #800000">total</span><span style="color: #800000">"</span>]                  <span style="color: #008000">#</span><span style="color: #008000"> 获取查询结果的总条数</span>
<span style="color: #000000">
            hit_list </span>= []                                           <span style="color: #008000">#</span><span style="color: #008000"> 设置一个列表来储存搜索到的信息，返回给html页面</span>


            <span style="color: #0000ff">for</span> hit <span style="color: #0000ff">in</span> response[<span style="color: #800000">"</span><span style="color: #800000">hits</span><span style="color: #800000">"</span>][<span style="color: #800000">"</span><span style="color: #800000">hits</span><span style="color: #800000">"</span>]:                                <span style="color: #008000">#</span><span style="color: #008000"> 循环查询到的结果</span>
                hit_dict = {}                                                   <span style="color: #008000">#</span><span style="color: #008000"> 设置一个字典来储存循环结果</span>
                <span style="color: #0000ff">if</span> <span style="color: #800000">"</span><span style="color: #800000">title</span><span style="color: #800000">"</span> <span style="color: #0000ff">in</span> hit[<span style="color: #800000">"</span><span style="color: #800000">highlight</span><span style="color: #800000">"</span>]:                                 <span style="color: #008000">#</span><span style="color: #008000"> 判断title字段，如果高亮字段有类容</span>
                    hit_dict[<span style="color: #800000">"</span><span style="color: #800000">title</span><span style="color: #800000">"</span>] = <span style="color: #800000">""</span>.join(hit[<span style="color: #800000">"</span><span style="color: #800000">highlight</span><span style="color: #800000">"</span>][<span style="color: #800000">"</span><span style="color: #800000">title</span><span style="color: #800000">"</span>])      <span style="color: #008000">#</span><span style="color: #008000"> 获取高亮里的title</span>
                <span style="color: #0000ff">else</span><span style="color: #000000">:
                    hit_dict[</span><span style="color: #800000">"</span><span style="color: #800000">title</span><span style="color: #800000">"</span>] = hit[<span style="color: #800000">"</span><span style="color: #800000">_source</span><span style="color: #800000">"</span>][<span style="color: #800000">"</span><span style="color: #800000">title</span><span style="color: #800000">"</span>]                 <span style="color: #008000">#</span><span style="color: #008000"> 否则获取不是高亮里的title</span>
<span style="color: #000000">
                hit_dict[</span><span style="color: #800000">"</span><span style="color: #800000">id</span><span style="color: #800000">"</span>] = hit[<span style="color: #800000">"</span><span style="color: #800000">_source</span><span style="color: #800000">"</span>][<span style="color: #800000">"</span><span style="color: #800000">nid</span><span style="color: #800000">"</span>]                          <span style="color: #008000">#</span><span style="color: #008000"> 获取返回nid</span>

                <span style="color: #008000">#</span><span style="color: #008000"> 加密样音地址</span>
                hit_dict[<span style="color: #800000">"</span><span style="color: #800000">yangsrc</span><span style="color: #800000">"</span>] = jia_mi(str(hit[<span style="color: #800000">"</span><span style="color: #800000">_source</span><span style="color: #800000">"</span>][<span style="color: #800000">"</span><span style="color: #800000">yangsrc</span><span style="color: #800000">"</span>]))    <span style="color: #008000">#</span><span style="color: #008000"> 获取返回yangsrc</span>
<span style="color: #000000">
                hit_list.append(hit_dict)     </span></pre>
</div>
<p>&nbsp;</p></div>