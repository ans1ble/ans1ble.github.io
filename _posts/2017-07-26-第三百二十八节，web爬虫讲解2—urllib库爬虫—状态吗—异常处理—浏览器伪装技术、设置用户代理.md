
---
layout: post
title: " 第三百二十八节，web爬虫讲解2—urllib库爬虫—状态吗—异常处理—浏览器伪装技术、设置用户代理 "
author: "Ans1ble"
header-style: text
tags:
      - Python
---


**第三百二十八节，web爬虫讲解2—urllib库爬虫—状态吗—异常处理—浏览器伪装技术、 ** **设置用户代理******

**如果爬虫没有异常处理，那么爬行中一旦出现错误，程序将崩溃停止工作，有异常处理即使出现错误也能继续执行下去**



**1.常见状态吗**

**301：重定向到新的URL，永久性**  
 **302：重定向到临时URL，非永久性**  
 **304：请求的资源未更新**  
 **400：非法请求**  
 **401：请求未经授权**  
 **403：禁止访问**  
 **404：没找到对应页面**  
 **500：服务器内部出现错误**  
 **501：服务器不支持实现请求所需要的功能**



**2.异常处理**

**URLError 捕获异常信息**

[code]

    #!/usr/bin/env python
    # -*- coding: utf-8 -*-
    
    import urllib.request
    import urllib.error
    
    try:                                    #尝试执行里面的内容
        html = urllib.request.urlopen('http://www.xiaohuar.com/').read().decode("utf-8")
        print(html)
    
    except urllib.error.URLError as e:      #如果出现错误
        if hasattr(e,"code"):               #如果有错误代码
            print(e.code)                   #打印错误代码
        if hasattr(e,"reason"):             #如果有错误信息
            print(e.reason)                 #打印错误信息
    
    #返回   说明网站禁止了爬虫访问
    # 403
    # Forbidden
[/code]



**浏览器伪装技术**

**很多网站，做了反爬技术，一般在后台检测请求头信息里是否有 User-Agent浏览器信息，如果没有说明不是浏览器访问，就屏蔽了这次请求**

**所以，我们需要伪装浏览器报头来请求**



[code]

    #!/usr/bin/env python
    # -*- coding: utf-8 -*-
    
    import urllib.request
    url = 'https://www.qiushibaike.com/'                    #抓取页面URL
    tou = ('User-Agent','Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0')  #设置模拟浏览器报头
    b_tou = urllib.request.build_opener()               #创建请求对象
    b_tou.addheaders=[tou]                              #添加报头
    html = b_tou.open(url).read().decode("utf-8")       #开始抓取页面
    print(html)
[/code]



**注意：我们可以看到这次请求并不是用urlopen()方法请求的，此时用urlopen()无法请求，但是我们就会感觉到这样很费劲，难道每次请求都要创建build_opener()，所以我们需要设置使用urlopen()方法请求自动报头**



****设置使用urlopen()方法请求自动报头，也就是设置用户代理****

****install_opener() 将报头信息设置为全局，urlopen()方法请求时也会自动添加报头****

[code]

    #!/usr/bin/env python
    # -*- coding: utf-8 -*-
    
    import urllib.request
    #设置报头信息
    tou = ('User-Agent','Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0')  #设置模拟浏览器报头
    b_tou = urllib.request.build_opener()               #创建请求对象
    b_tou.addheaders=[tou]                              #添加报头到请求对象
    #将报头信息设置为全局，urlopen()方法请求时也会自动添加报头
    urllib.request.install_opener(b_tou)
    
    #请求
    url = 'https://www.qiushibaike.com/'
    html = urllib.request.urlopen(url).read().decode("utf-8")
    print(html)
[/code]



**创建用户代理池**



[code]

    #!/usr/bin/env python
    # -*- coding: utf-8 -*-
    
    import urllib.request
    import random   #引入随机模块文件
    
    def yh_dl():    #创建用户代理池
        yhdl = [
            'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50',
            'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0',
            'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0)',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1',
            'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1',
            'Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; en) Presto/2.8.131 Version/11.11',
            'Opera/9.80 (Windows NT 6.1; U; en) Presto/2.8.131 Version/11.11',
            'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Maxthon 2.0)',
            'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; TencentTraveler 4.0)',
            'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)',
            'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; The World)',
            'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; 360SE)',
            'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Avant Browser)',
            'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)',
            'Mozilla/5.0 (iPhone; U; CPU iPhone OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5',
            'User-Agent:Mozilla/5.0 (iPod; U; CPU iPhone OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5',
            'Mozilla/5.0 (iPad; U; CPU OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5',
            'Mozilla/5.0 (Linux; U; Android 2.3.7; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1',
            'Opera/9.80 (Android 2.3.4; Linux; Opera Mobi/build-1107180945; U; en-GB) Presto/2.8.149 Version/11.10',
            'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13',
            'Mozilla/5.0 (BlackBerry; U; BlackBerry 9800; en) AppleWebKit/534.1+ (KHTML, like Gecko) Version/6.0.0.337 Mobile Safari/534.1+',
            'Mozilla/5.0 (compatible; MSIE 9.0; Windows Phone OS 7.5; Trident/5.0; IEMobile/9.0; HTC; Titan)',
            'UCWEB7.0.2.37/28/999',
            'NOKIA5700/ UCWEB7.0.2.37/28/999',
            'Openwave/ UCWEB7.0.2.37/28/999',
            'Mozilla/4.0 (compatible; MSIE 6.0; ) Opera/UCWEB7.0.2.37/28/999'
            ]
        thisua = random.choice(yhdl)                    #随机获取代理信息
        headers = ("User-Agent",thisua)                 #拼接报头信息
        opener = urllib.request.build_opener()          #创建请求对象
        opener.addheaders=[headers]                     #添加报头到请求对象
        urllib.request.install_opener(opener)           #将报头信息设置为全局，urlopen()方法请求时也会自动添加报头
    
    
    #请求
    yh_dl()     #执行用户代理池函数
    url = 'https://www.qiushibaike.com/'
    html = urllib.request.urlopen(url).read().decode("utf-8")
    print(html)
[/code]



**这样爬虫会随机调用，用户代理，也就是随机报头，保证每次报头信息不一样**



